\chapter{Introduction}

About three decades ago, the first minimally invasive surgery was performed. This was a huge step forward, as minimally invasive surgery offers several advantages compared to traditional surgery, such as less pain and less recovery time needed afterwards \cite{minimallyinvasive}. Intiuitively, this kind of operation is harder to perform, as it is conducted only through a small hole in the patient. The surgeon inserts an endoscope into the patient and only sees the 2D images without any depth.
Medical personell could profit from computers assisting them during surgery, by annotating the video frames with the used tools' positions and rotations and this way cover for the missing depth informtation to some extend. \

The task of annotating images with 3D objects is called 6D pose estimation and is already used and applied in various fields, e.g. robotics, augmented reality, medical imaging, and many more. For well-textured clearly visible objects the task is considered solved. Methods like Lowe's \cite{dglowe1} rely on detecting sparse features, for example keypoints, which are matched against a database that contains the corresponding pose.
Unfortunately, these approaches only work for objects with a strong and also visible texture. After cheap depth sensors like the Xbox Kinect became available, depth-based pose estimation procedures were able to achieve good results on texture-less but unoccluded and undeformed objects. Many of those methods match the image against a database of templates to recover the pose. \

These techniques have in common that they are non-learning based, i.e. there is no learning procedure which learns an object's appearancen through training data. Brachman et al. on the other hand used random forests and object coordinates to achieve good results on the occlusion dataset \cite{brachmann1}. The forests were trained to output the 3D object coordinate for an image patch. Using the 2D-3D correspondences, a robust estimate of the object's pose can be computed. With the breakthrough of neural networks in 2012 \cite{imagenet}, a lot of research in the area of learning-based methods was spawned. The so called \textit{Convolutional Neural Networks (CNNs)} offer outstanding accuracy that beat most traditional computer vision algorithms \cite{ylecun}. There already exist works, like \cite{akrull}, that combine the idea of learning the 3D coordinates of an object with the power of CNNs. Most learning-based pose estimation systems still need depth to achieve good results, though. But depth is usually not available in medical settings. A major drawbacks of neural networks is the need for data that can be learned from. In contrast to earlier methods, the data needs to be present upfront and annotated in some manner. \

The goal of this work is to create a program that enables a user to annotate the position and rotation of an object on an image, and thus create the necessary amounts of training data to train a network for precise 6D pose estimation in surgical videos. Although the program is versatile and can be used to annotate arbitrary data, it is created with the medical images in mind, that were provided at the beginning of the project and which also provided segmentation masks. To support the user in the still tedious task of annotating images, the goal is also to develop a neural network for pose estimation. To achieve state-of-the art results, the architecture of the network is \textit{ResNet} \cite{resnet}. ResNet is a network architecture from 2015, which allows for deeper networks by "carrying" the input to the deeper layers, which usually results in vanishing gradients. Similarily to Brachmann et al., the network predicts object coordinates on an image patch. But since segmentation images are already provided by the medical data, the focus is only on coordinate prediction and not instance segmentation. \

The remainder of the work is structured as follows: to qualify the ready to understand the subsequent chapters, an introduction into neural networks and 6D pose estimation is given in chapter \ref{chapter:background}. Chapter \ref{chapter:related_work} then introduces and discusses the latest research in the area of pose estimation, after giving a brief overview over earlier methods. The program's structure and usage along with visual explanations are presented in chapter \ref{chapter:program}. The mentioned network is described in chapter \ref{chapter:network}. The datasets used for the experiments conducted with the network are listed in chapter \ref{chapter:network} and the experiments are discussed in length in chapter \ref{chapter:experiments}. Last but not least, chapter \ref{chapter:conclusions} summarizes this work, draws related conclusions and gives a prospect into further possible research based on this work.