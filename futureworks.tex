\chapter{Future Works} \label{chapter:future_work}

To provide an outlook how the manual annotation process can be improved in the future, we provide some suggestions here. An important feature that should be implemented in \ac{6dpat} is allowing to move the object models around on the displayed image by dragging and them using the mouse. The initial poses using the clicking procedure are already sufficiently accurate in many cases. But when the camera is looking along an axis of the object, the position can be far off. The user can correct these poses with the provided controls. But the implemented rotation feature indicates that editing a pose by mouse can be faster which probably also holds for the position of an object.

The binding of the neural network to the program does not allow to load the weights of the net and persist this state in the memory of the computer. In case that the user wants to annotate a large dataset of just one object, they could profit from a feature allowing to keep the weights in memory instead of loading them each time the inference process is started. This way, predicting the pose for only one image could be achieved in significantly less time. Running the network to predict the pose of one object in a large amount of images amortizes the loading of the weights.

Another suggested step is to fully incorporate the network in the annotation tool. This way, inexperienced users can profit from the network without the need for an expert to run the network inference. There is probably no way to automatize the setup process, as this requires knowledge neural networks. In an ideal setting, this interference can be reduced to a minimum and users are introduced to the most relevant parameters only, which they can set from within the program.

In its current state, the neural networks can primarily be used to recover poses on images similar to the ones they were trained on. The data we obtained from the training process indicates that even deeper architectures should be explored to improve the accuracy on the test images. But beforehand the issue of the severe performance drop between the validation and test images needs investigation. 

A more fine-grained analysis of the incremental training scheme might lead to a similar performance like training from scratch. One option is to take images used for training in prior experiments for training again, but reduce the number of epochs at the same time. Intuitively, this probably leads to a higher validation and test error at the beginning but this could prevent the very noisy loss of the incremental experiments.

More elaborate measures of the accuracy of the network on unseen image could improve the active learning scheme. Instead only taking the intersection over union of the ground-truth and predicted segmentation masks into account, another possibility is to suggest images for annotation by computing the reprojection error and selecting the images with the highest error.